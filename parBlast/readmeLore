Para que funcionara el paralelizaje, hice una public key que le pase a mazorca para que permitiera a mazorca escribir en Leia sin pedir autorizacion.

 grep '>' Concatenados.faa | wc
Tengo 123762 secuencias en el concatenados.faa
Como quiero partir en 8 jobs divido
123762/8 approx 15471
y voy a usar 15471 secuencias por job

Correr el script 3 
./3.split_multifasta.pl --in=/home/nelly/Escritorio/parBlast/Concatenados.faa --output_dir=/home/nelly/Escritorio/parBlast/input_split_blast --seqs_per_file=15471

pusimos en fasta file los aqrchivos a procesar
al final borramos fasta file del ultimo row de fasta files
ls > fasta_files.txt

mkdir BETO_CLUSTER


Ahora lo repito para el arbol completo
1006275       
16 jobs       
igual 62290 secuencias por job
(va a tardar un aprox de 6 veces mas)

primero hago la base de datos total (En mi compu)
makeblastdb -in Concatenados.faa -dbtype prot -out Concatenados

Luego parto con el BEto script 3
# you need to create the output directory prior to use
# you need to use explicit directories, not ~/
./3.split_multifasta.pl --in=/home/nelly/Escritorio/ActinoTree/Genomas/Concatenados.faa --output_dir=/home/nelly/Escritorio/ActinoTree/input_split_blast --seqs_per_file=343900

Como me quedaron 16 archivos, cree el fasta_files.txt 
cd input_split_blast
ls *.fsa | sort -g >fasta_files.txt
(lista 1.fsa\n...16.fsa) y lo puse en mazorca en la carpeta BETO_CLUSTER

Borro los logs en Mazorca
Comento las líneas
#system($instruction);

y descomento el print

En el nodo maestro
./4.blast.iMac-nodes.pl

y después descomento el system y comento el print


fasta_files.txt                                                                                                             100%  103     0.1KB/s   00:00    
nelly@10.10.100.156:/home/nelly/Escritorio/ActinoTree/input_split_blast/1.fsa -> /home/nselem/LOGS/1.log

324574.mazorka
nelly@10.10.100.156:/home/nelly/Escritorio/ActinoTree/input_split_blast/2.fsa -> /home/nselem/LOGS/2.log

324575.mazorka
nelly@10.10.100.156:/home/nelly/Escritorio/ActinoTree/input_split_blast/3.fsa -> /home/nselem/LOGS/3.log
####################################################

MONITOREO

Te fijas en tu job id
Luego en el nodo maestro: pbsnodes -a | grep 'jobid'
En algún lugar de esa línea se encuentra el nombre del nodo donde corre el job

ssh nselem@node21
cd /scratch/nselem
tail

(Salir del nodo exit)

Según yo hoy mismo termina tu job, me puse a ver cuanto le falta al tanteo
ok, ya vi como encontrar el nodo
como viste "al tanteo"
Comparando los ids del FASTA con.los del archivo de salida .tab
Un tail a  5.fsa
Y otro tail a 5.tab
Comparas los ids y como los pegs están numerados en orden y con el id del genoma uno se puede dar una idea
Hay comandos más elegantes, pero como el BLAST está pesado, no conviene
El tail es ligero y con tus datos se presta para eso
mm donde estan esos archivos?
en SCRTCH?
Sí: cd \scratch\nselem
Con las diagonales al revés, no tengo la diagonal apropiada en mi cel
ok, sí, ya va a acabar
bueno Beto gracias, Emoticono grin
Ya casi ega berni por xime
De nada Nelly
Sale aquí espero

#################################################################
CONCATENADO
ok, y uego solo cat 1.tab 2.tab ... 8.tab >Total.tab
y ya os pega en orden no??
como me dijiste que era si tenia más de 10??
Dejame ver, lo tengo en mis notas Emoticono tongue
O puedes hacer: cat *.tab > total.tab
En tu caso
y lo hace en orden
vdd??
Si
ls *.tab | sort -g | xargs cat
Por si tienes más de 10 archivos y los quieres concatenar en orden numérico


